{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import scipy.signal as signal\n",
    "import webrtcvad\n",
    "from asteroid.models import DCCRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawnyzy/miniconda3/envs/venv1/lib/python3.11/site-packages/asteroid/models/base_models.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  conf = torch.load(cached_model, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# === DEVICE SETUP ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True  # Optional: improves performance for fixed input sizes\n",
    "\n",
    "# === Load pretrained Asteroid model ===\n",
    "model = DCCRNet.from_pretrained(\"JorisCos/DCCRNet_Libri1Mix_enhsingle_16k\")\n",
    "model.to(device)\n",
    "\n",
    "# === SAFE FILTERING HELPERS ===\n",
    "def safe_cutoff(cutoff, sr, margin=0.95):\n",
    "    nyquist = 0.5 * sr\n",
    "    return min(cutoff, nyquist * margin)\n",
    "\n",
    "# === AUDIO ENHANCEMENT FUNCTIONS ===\n",
    "def bandpass_filter(audio, sr, lowcut=80, highcut=3400, order=4):\n",
    "    nyquist = 0.5 * sr\n",
    "    low = safe_cutoff(lowcut, sr) / nyquist\n",
    "    high = safe_cutoff(highcut, sr) / nyquist\n",
    "    if low >= high or high >= 1.0:\n",
    "        return audio\n",
    "    sos = signal.butter(order, [low, high], btype='band', output='sos')\n",
    "    return signal.sosfilt(sos, audio)\n",
    "\n",
    "def apply_eq(audio, sr):\n",
    "    try:\n",
    "        b1, a1 = signal.iirpeak(100 / (0.5 * sr), Q=1.0)\n",
    "        audio = signal.lfilter(b1, a1, audio)\n",
    "        audio *= 1.5\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        b2, a2 = signal.iirpeak(3000 / (0.5 * sr), Q=1.5)\n",
    "        audio = signal.lfilter(b2, a2, audio)\n",
    "        audio *= 1.2\n",
    "    except:\n",
    "        pass\n",
    "    return audio\n",
    "\n",
    "def low_shelf_filter(audio, sr, cutoff=200, gain_db=6):\n",
    "    cutoff = safe_cutoff(cutoff, sr)\n",
    "    if cutoff <= 0:\n",
    "        return audio\n",
    "    gain = 10**(gain_db / 20)\n",
    "    b, a = signal.butter(1, cutoff / (0.5 * sr), btype='low')\n",
    "    return signal.lfilter(b, a, audio) * gain\n",
    "\n",
    "def high_shelf_filter(audio, sr, cutoff=4000, gain_db=4):\n",
    "    cutoff = safe_cutoff(cutoff, sr)\n",
    "    if cutoff >= 0.5 * sr:\n",
    "        return audio\n",
    "    gain = 10**(gain_db / 20)\n",
    "    b, a = signal.butter(1, cutoff / (0.5 * sr), btype='high')\n",
    "    return signal.lfilter(b, a, audio) * gain\n",
    "\n",
    "def compressor_limiter(audio, threshold_db=-20, ratio=4.0, makeup_gain_db=6):\n",
    "    threshold = 10**(threshold_db / 20)\n",
    "    makeup_gain = 10**(makeup_gain_db / 20)\n",
    "    def compress_sample(x):\n",
    "        abs_x = abs(x)\n",
    "        if abs_x < threshold:\n",
    "            return x\n",
    "        else:\n",
    "            compressed = threshold + (abs_x - threshold) / ratio\n",
    "            return np.sign(x) * compressed\n",
    "    compressed = np.array([compress_sample(x) for x in audio])\n",
    "    return compressed * makeup_gain\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    return audio / max_val if max_val > 0 else audio\n",
    "\n",
    "# === SPECTRAL NOISE GATE ===\n",
    "def spectral_noise_gate(audio, sr, gate_threshold_db=-40):\n",
    "    stft = librosa.stft(audio, n_fft=1024, hop_length=256)\n",
    "    magnitude, phase = np.abs(stft), np.angle(stft)\n",
    "    db_mag = librosa.amplitude_to_db(magnitude)\n",
    "    gate_mask = db_mag > gate_threshold_db\n",
    "    gated_mag = magnitude * gate_mask\n",
    "    stft_gated = gated_mag * np.exp(1j * phase)\n",
    "    return librosa.istft(stft_gated, hop_length=256)\n",
    "\n",
    "# === VAD CLEANING USING WEBRTC ===\n",
    "def remove_non_speech_segments(audio, sr, aggressiveness=2):\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "    window_duration = 30  # ms\n",
    "    samples_per_window = int(sr * window_duration / 1000)\n",
    "    bytes_per_sample = 2\n",
    "\n",
    "    # Convert to 16-bit PCM\n",
    "    int16_audio = np.int16(audio * 32768)\n",
    "    pcm_audio = int16_audio.tobytes()\n",
    "\n",
    "    voiced_audio = bytearray()\n",
    "    for i in range(0, len(pcm_audio), samples_per_window * bytes_per_sample):\n",
    "        window = pcm_audio[i:i + samples_per_window * bytes_per_sample]\n",
    "        if len(window) < samples_per_window * bytes_per_sample:\n",
    "            break\n",
    "        if vad.is_speech(window, sample_rate=sr):\n",
    "            voiced_audio.extend(window)\n",
    "\n",
    "    # Convert back to float32\n",
    "    if len(voiced_audio) == 0:\n",
    "        return audio  # fallback\n",
    "    voiced_np = np.frombuffer(voiced_audio, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "    return voiced_np\n",
    "\n",
    "# === ASTEROID ENHANCEMENT ===\n",
    "def enhance_with_asteroid_chunked(input_path, tmp_output_path, target_sr=16000, chunk_size=10):\n",
    "    waveform, sr = torchaudio.load(input_path)\n",
    "    if sr != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "    waveform = waveform.mean(dim=0, keepdim=True)  # mono\n",
    "\n",
    "    chunk_len = chunk_size * target_sr  # e.g., 10 seconds\n",
    "    total_len = waveform.shape[-1]\n",
    "\n",
    "    enhanced_audio = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, total_len, chunk_len):\n",
    "            end = min(start + chunk_len, total_len)\n",
    "            chunk = waveform[:, start:end].to(device)\n",
    "            try:\n",
    "                enhanced = model.separate(chunk)[0].squeeze(0).cpu().numpy()\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error on chunk {start}-{end}: {e}\")\n",
    "                continue\n",
    "            enhanced_audio.append(enhanced)\n",
    "\n",
    "    full_audio = np.concatenate(enhanced_audio, axis=-1)\n",
    "    sf.write(tmp_output_path, full_audio, target_sr)\n",
    "    return tmp_output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_atc_audio_asteroid_vad(input_folder):\n",
    "    output_folder = input_folder.rstrip('/\\\\') + '-asteroid-vad-enhanced'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.lower().endswith('.wav'):\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            tmp_path = os.path.join(\"tmp_asteroid_clean.wav\")\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "            print(f\"ðŸ”Š Processing: {file_name}\")\n",
    "            try:\n",
    "                # ML Denoising Step\n",
    "                enhanced_path = enhance_with_asteroid_chunked(input_path, tmp_path)\n",
    "\n",
    "                # Load enhanced audio\n",
    "                audio, sr = librosa.load(enhanced_path, sr=None)\n",
    "\n",
    "                # Remove static-only parts using VAD\n",
    "                audio = remove_non_speech_segments(audio, sr)\n",
    "\n",
    "                # Traditional Enhancements\n",
    "                filtered = bandpass_filter(audio, sr)\n",
    "                equalized = apply_eq(filtered, sr)\n",
    "                shelved = low_shelf_filter(equalized, sr)\n",
    "                shelved = high_shelf_filter(shelved, sr)\n",
    "                compressed = compressor_limiter(shelved)\n",
    "                gated = spectral_noise_gate(compressed, sr)\n",
    "                normalized = normalize_audio(gated)\n",
    "\n",
    "                sf.write(output_path, normalized, sr)\n",
    "                print(f\"âœ… Saved to: {output_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Š Processing: 08NC15MBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/08NC15MBP_0101.wav\n",
      "ðŸ”Š Processing: NI66MBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/NI66MBQ_0101.wav\n",
      "ðŸ”Š Processing: NI56MBX_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/NI56MBX_0101.wav\n",
      "ðŸ”Š Processing: 15NC30MBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/15NC30MBQ_0101.wav\n",
      "ðŸ”Š Processing: NI06FBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/NI06FBP_0101.wav\n",
      "ðŸ”Š Processing: 28NC51MBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/28NC51MBP_0101.wav\n",
      "ðŸ”Š Processing: 09NC17FBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/09NC17FBP_0101.wav\n",
      "ðŸ”Š Processing: 15NC29FBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/15NC29FBP_0101.wav\n",
      "ðŸ”Š Processing: 08NC16FBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/08NC16FBQ_0101.wav\n",
      "ðŸ”Š Processing: 29NC54FBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/29NC54FBQ_0101.wav\n",
      "ðŸ”Š Processing: 29NC53MBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/29NC53MBP_0101.wav\n",
      "ðŸ”Š Processing: 14NC27MBP_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/14NC27MBP_0101.wav\n",
      "ðŸ”Š Processing: 09NC18MBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/09NC18MBQ_0101.wav\n",
      "ðŸ”Š Processing: 14NC28MBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/14NC28MBQ_0101.wav\n",
      "ðŸ”Š Processing: NI17FBQ_0101.wav\n",
      "âœ… Saved to: /home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files-asteroid-vad-enhanced/NI17FBQ_0101.wav\n"
     ]
    }
   ],
   "source": [
    "enhance_atc_audio_asteroid_vad('/home/shawnyzy/Documents/benchmarking-pipeline/datasets/zh-2-dev_en_separate/wav_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
